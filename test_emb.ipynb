{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21fd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import test_build_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import timm\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, nb_classes = test_build_dataset()\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet34.a1_in1k', pretrained=True, num_classes=nb_classes).to('cuda')\n",
    "model.load_state_dict(torch.load('models_para/resnet34.a1_in1k_ecgid_kd.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e5fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Embedding compression head (dim reduction + normalization).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, target_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.dim_reduction = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, target_dim),\n",
    "            nn.BatchNorm1d(target_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = nn.functional.normalize(self.dim_reduction(x), p=2, dim=1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = next(iter(dataloader_train))\n",
    "data, targets = data.to('cuda'), targets.to('cuda')\n",
    "\n",
    "embedding_head = EmbeddingHead(512, 128).to('cuda')\n",
    "features = model.forward_features(data)\n",
    "features = model.global_pool(features)\n",
    "# embs = embedding_head(features)\n",
    "# embs.shape\n",
    "embs = features\n",
    "embs = nn.functional.normalize(embs, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(batch_shape):\n",
    "    \"\"\"\n",
    "    加速正负样本的查找\n",
    "    \"\"\"\n",
    "    classes_num, embedding_num = batch_shape\n",
    "    batch_size = classes_num * embedding_num\n",
    "    negative_mask, positive_mask = torch.full(\n",
    "        (batch_size, batch_size), False), torch.full((batch_size, batch_size), True)\n",
    "    for s in range(0, batch_size, embedding_num):\n",
    "        for i in range(embedding_num):\n",
    "            for j in range(embedding_num):\n",
    "                negative_mask[s + i][s + j] = True \n",
    "    for s in range(0, batch_size, embedding_num):\n",
    "        for i in range(embedding_num):\n",
    "            for j in range(embedding_num):\n",
    "                positive_mask[s + i][s + j] = False\n",
    "    return positive_mask, negative_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e04e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = torch.cdist(embs, embs, p=2)\n",
    "\n",
    "# 生成掩码\n",
    "positive_mask, negative_mask = get_mask((embs.shape[0] // 4, 4))\n",
    "\n",
    "# 正样本与锚点的距离掩码\n",
    "pos_masked_matrix = distance_matrix.clone()\n",
    "pos_masked_matrix[positive_mask] = float('-inf')\n",
    "\n",
    "# 负样本与锚点的距离掩码\n",
    "neg_masked_matrix = distance_matrix.clone()\n",
    "neg_masked_matrix[negative_mask] = float('inf')\n",
    "\n",
    "# 32个锚点的对应的正样本\n",
    "_, hardest_positive_idxs = torch.max(pos_masked_matrix, dim=1)\n",
    "positives = embs[hardest_positive_idxs]\n",
    "\n",
    "# 32个锚点对应的负样本\n",
    "_, hardest_negative_idxs = torch.min(neg_masked_matrix, dim=1)\n",
    "negatives = embs[hardest_negative_idxs]\n",
    "\n",
    "print(\"dist_pos\", (embs - positives).norm(dim=1).mean().item())\n",
    "print(\"dist_neg\", (embs - negatives).norm(dim=1).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e3b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b330f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_list = [[round(x, 4) for x in row] for row in distance_matrix.tolist()]\n",
    "distance_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecgid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
